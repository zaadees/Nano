name: Run WK12

on:
  schedule:
    - cron: '0 */4 * * *'  # Run every 6 hours
  workflow_dispatch:  # Allow manual triggering
  push:
    branches: [ main ]

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
    - name: Check out repository
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
        
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y libxml2-dev libxslt1-dev

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install --only-binary=lxml -r requirements.txt

    - name: Run scrape
      run: |
        chmod +x scripts/washk12_job_scraper_direct.py
        ./scripts/washk12_job_scraper_direct.py --index

    - name: split history
      run: |
        chmod +x scripts/json_splitter.py
        ./scripts/json_splitter.py --id-key job_id washk12_jobs/index.json jobs wk12_history --clean

    - name: Commit and push if changes
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add -A
        git diff --quiet && git diff --staged --quiet || (git commit -m "Update scraped data")
        
    - name: Push changes
      uses: ad-m/github-push-action@master
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        branch: ${{ github.ref }}
