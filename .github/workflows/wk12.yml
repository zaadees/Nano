name: Run WK12

on:
  schedule:
    - cron: '0 */4 * * *'  # Run every 6 hours
  workflow_dispatch:  # Allow manual triggering
  push:
    branches: [ main ]

# Explicitly set permissions for the GITHUB_TOKEN
permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
    - name: Check out repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
        
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y libxml2-dev libxslt1-dev

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install --only-binary=lxml -r requirements.txt

    - name: Run scrape
      run: |
        chmod +x scripts/washk12_job_scraper_direct.py
        ./scripts/washk12_job_scraper_direct.py --index

    - name: split history
      run: |
        chmod +x scripts/json_splitter.py
        ./scripts/json_splitter.py --id-key job_id washk12_jobs/index.json jobs wk12_history --clean

    - name: Commit and push if changes
      run: |
        git config --local user.email "github-actions@github.com"
        git config --local user.name "GitHub Actions"
        git add -A
        if git diff --quiet && git diff --staged --quiet; then
          echo "No changes to commit"
        else
          git commit -m "Update scraped data"
          git push
        fi
